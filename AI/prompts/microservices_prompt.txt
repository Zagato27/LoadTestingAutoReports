ЗАДАЧА: Исчерпывающий отчет по всем метрикам микросервисов  в ходе ступенчатого нагрузочного тестирования

ИСХОДНЫЕ ДАННЫЕ:
- Все данные по среднему времени запросов (rate(nsi_query_seconds_sum)/rate(nsi_query_seconds_count))
- Все данные по количеству запросов (rate(nsi_query_seconds_count))
- Все другие доступные метрики по микросервисам

РЕКОМЕНДУЕМЫЕ SLA (по мировой практике):
- Время отклика (latency):
  * Нормальное: P95 < 200 мс
  * Предупреждение: P95 = 200-500 мс
  * Критическое: P95 > 500 мс
- Apdex (показатель удовлетворенности):
  * Целевое значение: ≥ 0.85
  * Минимально допустимое: ≥ 0.70
- Частота ошибок:
  * Нормальная: < 0.1% запросов
  * Предупреждение: 0.1-1% запросов
  * Критическая: > 1% запросов
- Доступность (uptime):
  * Целевая: 99.9% (не более 43 минут простоя в месяц)
  * Минимальная: 99.5% (не более 3.6 часов простоя в месяц)

ТРЕБОВАНИЯ К АНАЛИЗУ:
1. Проанализировать ВСЕ доступные метрики по ВСЕМ микросервисам
2. По каждой метрике и каждому микросервису предоставить:
   - Полный диапазон значений (мин/макс/среднее)
   - Все временные интервалы изменений
   - Сравнительный анализ между всеми сервисами
   - Соответствие рекомендуемым SLA

3. Выделить в анализе:
   - Время запроса (latency) по каждому микросервису в полном объеме
   - Количество запросов (RPS) по каждому микросервису в полном объеме
   - Все корреляции между метриками для каждого сервиса

СТРУКТУРА ОТВЕТА:
1. Анализ времени запроса (latency)
   • Полный анализ по ВСЕМ микросервисам без исключения
   • Все значения с указанием времени для каждого сервиса
   • Исчерпывающее сравнение между всеми сервисами
   • Соответствие целевым SLA по времени отклика

2. Анализ количества запросов (RPS)
   • Детальный анализ RPS по всем микросервисам
   • Все пиковые значения с точным временем
   • Полная динамика изменений для каждого сервиса
   • Сравнение с максимальной пропускной способностью

3. Связь нагрузки и латенси
   • Исчерпывающий анализ корреляций для каждого сервиса
   • Все случаи зависимости времени ответа от нагрузки
   • Полное описание поведения сервисов при различных нагрузках
   • Оценка соответствия SLA при различных уровнях нагрузки

4. Итоговые выводы
   • Обобщение по всем проанализированным метрикам
   • Сравнительный анализ всех микросервисов
   • Конкретные рекомендации для каждого сервиса
   • Общая оценка соответствия SLA и предложения по оптимизации

ВАЖНО:
1. НЕ ПРИДУМЫВАТЬ ДАННЫХ. Если в исходных отчетах что-то не указано, отметить это как пробел в данных.
2. НЕ ДЕЛАТЬ ПРЕДПОЛОЖЕНИЙ о причинах и следствиях, если они не очевидны из числовых данных.
3. НЕ ВВОДИТЬ НОВЫХ ТЕРМИНОВ или метрик, которых нет в исходных отчетах.
4. При невозможности сделать вывод из-за недостаточности данных — честно указать на это.
5. Использовать только те числовые значения, которые явно приведены в исходных отчетах.
6. Включите в анализ данные по всем микросервисам, даже если некоторые из них имеют незначительные показатели. Не пропускайте никакие метрики.


ФОРМАТ ОТВЕТА:
- Отвечайте строго в JSON со схемой: {verdict, confidence, findings[], recommended_actions[]}.
- Если данных недостаточно, верните verdict: "insufficient_data" и укажите причину в findings.

ПРИМЕР ОТВЕТА (JSON):
```json
{
  "verdict": "норма",
  "confidence": 0.74,
  "findings": [
    "Среднее время ответа стабильно, P95 < 250мс на всех сервисах",
    {"summary": "RPS вырос на 30% без деградации latency на micro-registry-nsi"}
  ],
  "recommended_actions": [
    "Добавить алерт P95>300мс для всех сервисов",
    "Проверить лимиты CPU для micro-address-search-node"
  ]
}
```